{
  "best_metric": 0.8798502683639526,
  "best_model_checkpoint": "lora/mT5_multilingual_XLSum/checkpoint-13380",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 13380,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.19,
      "grad_norm": 0.18029430508613586,
      "learning_rate": 0.0009962630792227205,
      "loss": 1.0521,
      "step": 500
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.21858802437782288,
      "learning_rate": 0.000992526158445441,
      "loss": 1.0619,
      "step": 1000
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2250460684299469,
      "learning_rate": 0.0009887892376681615,
      "loss": 1.041,
      "step": 1500
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.22354447841644287,
      "learning_rate": 0.000985052316890882,
      "loss": 1.0449,
      "step": 2000
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.2166696935892105,
      "learning_rate": 0.0009813153961136024,
      "loss": 1.0357,
      "step": 2500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.9056412577629089,
      "eval_runtime": 27.5241,
      "eval_samples_per_second": 54.498,
      "eval_steps_per_second": 6.83,
      "step": 2676
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.24878309667110443,
      "learning_rate": 0.000977578475336323,
      "loss": 1.0143,
      "step": 3000
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.25685855746269226,
      "learning_rate": 0.0009738415545590434,
      "loss": 1.0057,
      "step": 3500
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.3109933137893677,
      "learning_rate": 0.0009701046337817638,
      "loss": 0.9986,
      "step": 4000
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.25290027260780334,
      "learning_rate": 0.0009663677130044843,
      "loss": 1.0025,
      "step": 4500
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.2669682800769806,
      "learning_rate": 0.0009626307922272049,
      "loss": 1.0176,
      "step": 5000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8923477530479431,
      "eval_runtime": 27.5463,
      "eval_samples_per_second": 54.454,
      "eval_steps_per_second": 6.825,
      "step": 5352
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.23197071254253387,
      "learning_rate": 0.0009588938714499252,
      "loss": 0.9998,
      "step": 5500
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3009748160839081,
      "learning_rate": 0.0009551569506726457,
      "loss": 0.9758,
      "step": 6000
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.30045390129089355,
      "learning_rate": 0.0009514200298953663,
      "loss": 0.9751,
      "step": 6500
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.28009647130966187,
      "learning_rate": 0.0009476831091180868,
      "loss": 0.9988,
      "step": 7000
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.28467050194740295,
      "learning_rate": 0.0009439461883408071,
      "loss": 0.9899,
      "step": 7500
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.28690311312675476,
      "learning_rate": 0.0009402092675635277,
      "loss": 0.9821,
      "step": 8000
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8941808342933655,
      "eval_runtime": 27.55,
      "eval_samples_per_second": 54.446,
      "eval_steps_per_second": 6.824,
      "step": 8028
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.30089282989501953,
      "learning_rate": 0.0009364723467862482,
      "loss": 0.96,
      "step": 8500
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.2521691620349884,
      "learning_rate": 0.0009327354260089686,
      "loss": 0.9619,
      "step": 9000
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.26884955167770386,
      "learning_rate": 0.0009289985052316892,
      "loss": 0.9533,
      "step": 9500
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.2949866056442261,
      "learning_rate": 0.0009252615844544096,
      "loss": 0.9766,
      "step": 10000
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.31321433186531067,
      "learning_rate": 0.00092152466367713,
      "loss": 0.9698,
      "step": 10500
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.8810392022132874,
      "eval_runtime": 27.5611,
      "eval_samples_per_second": 54.425,
      "eval_steps_per_second": 6.821,
      "step": 10704
    },
    {
      "epoch": 4.11,
      "grad_norm": 0.30659738183021545,
      "learning_rate": 0.0009177877428998506,
      "loss": 0.9519,
      "step": 11000
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.33685147762298584,
      "learning_rate": 0.0009140508221225711,
      "loss": 0.9564,
      "step": 11500
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.31827467679977417,
      "learning_rate": 0.0009103139013452914,
      "loss": 0.9515,
      "step": 12000
    },
    {
      "epoch": 4.67,
      "grad_norm": 0.2880251109600067,
      "learning_rate": 0.000906576980568012,
      "loss": 0.9623,
      "step": 12500
    },
    {
      "epoch": 4.86,
      "grad_norm": 0.2936590313911438,
      "learning_rate": 0.0009028400597907325,
      "loss": 0.9534,
      "step": 13000
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.8798502683639526,
      "eval_runtime": 40.1621,
      "eval_samples_per_second": 37.349,
      "eval_steps_per_second": 4.681,
      "step": 13380
    }
  ],
  "logging_steps": 500,
  "max_steps": 133800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "total_flos": 1.294672507305984e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
