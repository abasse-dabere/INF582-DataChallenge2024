{
  "best_metric": 0.8923477530479431,
  "best_model_checkpoint": "lora/mT5_multilingual_XLSum/checkpoint-5352",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 8028,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.19,
      "grad_norm": 0.18029430508613586,
      "learning_rate": 0.0009962630792227205,
      "loss": 1.0521,
      "step": 500
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.21858802437782288,
      "learning_rate": 0.000992526158445441,
      "loss": 1.0619,
      "step": 1000
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2250460684299469,
      "learning_rate": 0.0009887892376681615,
      "loss": 1.041,
      "step": 1500
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.22354447841644287,
      "learning_rate": 0.000985052316890882,
      "loss": 1.0449,
      "step": 2000
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.2166696935892105,
      "learning_rate": 0.0009813153961136024,
      "loss": 1.0357,
      "step": 2500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.9056412577629089,
      "eval_runtime": 27.5241,
      "eval_samples_per_second": 54.498,
      "eval_steps_per_second": 6.83,
      "step": 2676
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.24878309667110443,
      "learning_rate": 0.000977578475336323,
      "loss": 1.0143,
      "step": 3000
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.25685855746269226,
      "learning_rate": 0.0009738415545590434,
      "loss": 1.0057,
      "step": 3500
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.3109933137893677,
      "learning_rate": 0.0009701046337817638,
      "loss": 0.9986,
      "step": 4000
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.25290027260780334,
      "learning_rate": 0.0009663677130044843,
      "loss": 1.0025,
      "step": 4500
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.2669682800769806,
      "learning_rate": 0.0009626307922272049,
      "loss": 1.0176,
      "step": 5000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8923477530479431,
      "eval_runtime": 27.5463,
      "eval_samples_per_second": 54.454,
      "eval_steps_per_second": 6.825,
      "step": 5352
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.23197071254253387,
      "learning_rate": 0.0009588938714499252,
      "loss": 0.9998,
      "step": 5500
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3009748160839081,
      "learning_rate": 0.0009551569506726457,
      "loss": 0.9758,
      "step": 6000
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.30045390129089355,
      "learning_rate": 0.0009514200298953663,
      "loss": 0.9751,
      "step": 6500
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.28009647130966187,
      "learning_rate": 0.0009476831091180868,
      "loss": 0.9988,
      "step": 7000
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.28467050194740295,
      "learning_rate": 0.0009439461883408071,
      "loss": 0.9899,
      "step": 7500
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.28690311312675476,
      "learning_rate": 0.0009402092675635277,
      "loss": 0.9821,
      "step": 8000
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8941808342933655,
      "eval_runtime": 27.55,
      "eval_samples_per_second": 54.446,
      "eval_steps_per_second": 6.824,
      "step": 8028
    }
  ],
  "logging_steps": 500,
  "max_steps": 133800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "total_flos": 7.768035043835904e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
