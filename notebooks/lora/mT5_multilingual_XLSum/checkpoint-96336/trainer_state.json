{
  "best_metric": 0.8639548420906067,
  "best_model_checkpoint": "lora/mT5_multilingual_XLSum/checkpoint-66900",
  "epoch": 36.0,
  "eval_steps": 500,
  "global_step": 96336,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.19,
      "grad_norm": 0.18029430508613586,
      "learning_rate": 0.0009962630792227205,
      "loss": 1.0521,
      "step": 500
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.21858802437782288,
      "learning_rate": 0.000992526158445441,
      "loss": 1.0619,
      "step": 1000
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2250460684299469,
      "learning_rate": 0.0009887892376681615,
      "loss": 1.041,
      "step": 1500
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.22354447841644287,
      "learning_rate": 0.000985052316890882,
      "loss": 1.0449,
      "step": 2000
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.2166696935892105,
      "learning_rate": 0.0009813153961136024,
      "loss": 1.0357,
      "step": 2500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.9056412577629089,
      "eval_runtime": 27.5241,
      "eval_samples_per_second": 54.498,
      "eval_steps_per_second": 6.83,
      "step": 2676
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.24878309667110443,
      "learning_rate": 0.000977578475336323,
      "loss": 1.0143,
      "step": 3000
    },
    {
      "epoch": 1.31,
      "grad_norm": 0.25685855746269226,
      "learning_rate": 0.0009738415545590434,
      "loss": 1.0057,
      "step": 3500
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.3109933137893677,
      "learning_rate": 0.0009701046337817638,
      "loss": 0.9986,
      "step": 4000
    },
    {
      "epoch": 1.68,
      "grad_norm": 0.25290027260780334,
      "learning_rate": 0.0009663677130044843,
      "loss": 1.0025,
      "step": 4500
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.2669682800769806,
      "learning_rate": 0.0009626307922272049,
      "loss": 1.0176,
      "step": 5000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8923477530479431,
      "eval_runtime": 27.5463,
      "eval_samples_per_second": 54.454,
      "eval_steps_per_second": 6.825,
      "step": 5352
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.23197071254253387,
      "learning_rate": 0.0009588938714499252,
      "loss": 0.9998,
      "step": 5500
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.3009748160839081,
      "learning_rate": 0.0009551569506726457,
      "loss": 0.9758,
      "step": 6000
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.30045390129089355,
      "learning_rate": 0.0009514200298953663,
      "loss": 0.9751,
      "step": 6500
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.28009647130966187,
      "learning_rate": 0.0009476831091180868,
      "loss": 0.9988,
      "step": 7000
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.28467050194740295,
      "learning_rate": 0.0009439461883408071,
      "loss": 0.9899,
      "step": 7500
    },
    {
      "epoch": 2.99,
      "grad_norm": 0.28690311312675476,
      "learning_rate": 0.0009402092675635277,
      "loss": 0.9821,
      "step": 8000
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8941808342933655,
      "eval_runtime": 27.55,
      "eval_samples_per_second": 54.446,
      "eval_steps_per_second": 6.824,
      "step": 8028
    },
    {
      "epoch": 3.18,
      "grad_norm": 0.30089282989501953,
      "learning_rate": 0.0009364723467862482,
      "loss": 0.96,
      "step": 8500
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.2521691620349884,
      "learning_rate": 0.0009327354260089686,
      "loss": 0.9619,
      "step": 9000
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.26884955167770386,
      "learning_rate": 0.0009289985052316892,
      "loss": 0.9533,
      "step": 9500
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.2949866056442261,
      "learning_rate": 0.0009252615844544096,
      "loss": 0.9766,
      "step": 10000
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.31321433186531067,
      "learning_rate": 0.00092152466367713,
      "loss": 0.9698,
      "step": 10500
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.8810392022132874,
      "eval_runtime": 27.5611,
      "eval_samples_per_second": 54.425,
      "eval_steps_per_second": 6.821,
      "step": 10704
    },
    {
      "epoch": 4.11,
      "grad_norm": 0.30659738183021545,
      "learning_rate": 0.0009177877428998506,
      "loss": 0.9519,
      "step": 11000
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.33685147762298584,
      "learning_rate": 0.0009140508221225711,
      "loss": 0.9564,
      "step": 11500
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.31827467679977417,
      "learning_rate": 0.0009103139013452914,
      "loss": 0.9515,
      "step": 12000
    },
    {
      "epoch": 4.67,
      "grad_norm": 0.2880251109600067,
      "learning_rate": 0.000906576980568012,
      "loss": 0.9623,
      "step": 12500
    },
    {
      "epoch": 4.86,
      "grad_norm": 0.2936590313911438,
      "learning_rate": 0.0009028400597907325,
      "loss": 0.9534,
      "step": 13000
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.8798502683639526,
      "eval_runtime": 40.1621,
      "eval_samples_per_second": 37.349,
      "eval_steps_per_second": 4.681,
      "step": 13380
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.3110879063606262,
      "learning_rate": 0.0008991031390134529,
      "loss": 0.9318,
      "step": 13500
    },
    {
      "epoch": 5.23,
      "grad_norm": 0.3037430942058563,
      "learning_rate": 0.0008953662182361734,
      "loss": 0.9186,
      "step": 14000
    },
    {
      "epoch": 5.42,
      "grad_norm": 0.29458263516426086,
      "learning_rate": 0.0008916292974588939,
      "loss": 0.9297,
      "step": 14500
    },
    {
      "epoch": 5.61,
      "grad_norm": 0.29510805010795593,
      "learning_rate": 0.0008878923766816143,
      "loss": 0.9476,
      "step": 15000
    },
    {
      "epoch": 5.79,
      "grad_norm": 0.2950667142868042,
      "learning_rate": 0.0008841554559043349,
      "loss": 0.9649,
      "step": 15500
    },
    {
      "epoch": 5.98,
      "grad_norm": 0.31991633772850037,
      "learning_rate": 0.0008804185351270553,
      "loss": 0.9488,
      "step": 16000
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.8818785548210144,
      "eval_runtime": 27.5792,
      "eval_samples_per_second": 54.389,
      "eval_steps_per_second": 6.817,
      "step": 16056
    },
    {
      "epoch": 6.17,
      "grad_norm": 0.31804192066192627,
      "learning_rate": 0.0008766816143497757,
      "loss": 0.9261,
      "step": 16500
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.2976352274417877,
      "learning_rate": 0.0008729446935724963,
      "loss": 0.9268,
      "step": 17000
    },
    {
      "epoch": 6.54,
      "grad_norm": 0.2710359990596771,
      "learning_rate": 0.0008692077727952168,
      "loss": 0.9195,
      "step": 17500
    },
    {
      "epoch": 6.73,
      "grad_norm": 0.3379325270652771,
      "learning_rate": 0.0008654708520179372,
      "loss": 0.9448,
      "step": 18000
    },
    {
      "epoch": 6.91,
      "grad_norm": 0.3213713765144348,
      "learning_rate": 0.0008617339312406577,
      "loss": 0.9394,
      "step": 18500
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.876674473285675,
      "eval_runtime": 27.5561,
      "eval_samples_per_second": 54.434,
      "eval_steps_per_second": 6.822,
      "step": 18732
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.27229946851730347,
      "learning_rate": 0.0008579970104633782,
      "loss": 0.9255,
      "step": 19000
    },
    {
      "epoch": 7.29,
      "grad_norm": 0.3062897324562073,
      "learning_rate": 0.0008542600896860987,
      "loss": 0.9161,
      "step": 19500
    },
    {
      "epoch": 7.47,
      "grad_norm": 0.28627362847328186,
      "learning_rate": 0.0008505231689088192,
      "loss": 0.9204,
      "step": 20000
    },
    {
      "epoch": 7.66,
      "grad_norm": 0.3106400966644287,
      "learning_rate": 0.0008467862481315396,
      "loss": 0.9241,
      "step": 20500
    },
    {
      "epoch": 7.85,
      "grad_norm": 0.3226792514324188,
      "learning_rate": 0.0008430493273542601,
      "loss": 0.9319,
      "step": 21000
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.873462975025177,
      "eval_runtime": 28.9783,
      "eval_samples_per_second": 51.763,
      "eval_steps_per_second": 6.488,
      "step": 21408
    },
    {
      "epoch": 8.03,
      "grad_norm": 0.29079556465148926,
      "learning_rate": 0.0008393124065769806,
      "loss": 0.9203,
      "step": 21500
    },
    {
      "epoch": 8.22,
      "grad_norm": 0.34226444363594055,
      "learning_rate": 0.0008355754857997011,
      "loss": 0.9153,
      "step": 22000
    },
    {
      "epoch": 8.41,
      "grad_norm": 0.30965739488601685,
      "learning_rate": 0.0008318385650224215,
      "loss": 0.9147,
      "step": 22500
    },
    {
      "epoch": 8.59,
      "grad_norm": 0.3769981861114502,
      "learning_rate": 0.000828101644245142,
      "loss": 0.9152,
      "step": 23000
    },
    {
      "epoch": 8.78,
      "grad_norm": 0.30906352400779724,
      "learning_rate": 0.0008243647234678625,
      "loss": 0.9212,
      "step": 23500
    },
    {
      "epoch": 8.97,
      "grad_norm": 0.36080461740493774,
      "learning_rate": 0.000820627802690583,
      "loss": 0.9091,
      "step": 24000
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.8734257817268372,
      "eval_runtime": 54.3939,
      "eval_samples_per_second": 27.577,
      "eval_steps_per_second": 3.456,
      "step": 24084
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.35190367698669434,
      "learning_rate": 0.0008168908819133034,
      "loss": 0.8967,
      "step": 24500
    },
    {
      "epoch": 9.34,
      "grad_norm": 0.30203497409820557,
      "learning_rate": 0.0008131539611360239,
      "loss": 0.8994,
      "step": 25000
    },
    {
      "epoch": 9.53,
      "grad_norm": 0.3544522821903229,
      "learning_rate": 0.0008094170403587444,
      "loss": 0.9082,
      "step": 25500
    },
    {
      "epoch": 9.72,
      "grad_norm": 0.37940099835395813,
      "learning_rate": 0.0008056801195814649,
      "loss": 0.9212,
      "step": 26000
    },
    {
      "epoch": 9.9,
      "grad_norm": 0.2831713855266571,
      "learning_rate": 0.0008019431988041853,
      "loss": 0.9185,
      "step": 26500
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.8785650134086609,
      "eval_runtime": 28.0108,
      "eval_samples_per_second": 53.551,
      "eval_steps_per_second": 6.712,
      "step": 26760
    },
    {
      "epoch": 10.09,
      "grad_norm": 0.3496060371398926,
      "learning_rate": 0.0007982062780269058,
      "loss": 0.897,
      "step": 27000
    },
    {
      "epoch": 10.28,
      "grad_norm": 0.3670955300331116,
      "learning_rate": 0.0007944693572496263,
      "loss": 0.896,
      "step": 27500
    },
    {
      "epoch": 10.46,
      "grad_norm": 0.3238270580768585,
      "learning_rate": 0.0007907324364723468,
      "loss": 0.8874,
      "step": 28000
    },
    {
      "epoch": 10.65,
      "grad_norm": 0.38212913274765015,
      "learning_rate": 0.0007869955156950673,
      "loss": 0.9052,
      "step": 28500
    },
    {
      "epoch": 10.84,
      "grad_norm": 0.2650419771671295,
      "learning_rate": 0.0007832585949177878,
      "loss": 0.9099,
      "step": 29000
    },
    {
      "epoch": 11.0,
      "eval_loss": 0.8693349361419678,
      "eval_runtime": 27.9744,
      "eval_samples_per_second": 53.621,
      "eval_steps_per_second": 6.72,
      "step": 29436
    },
    {
      "epoch": 11.02,
      "grad_norm": 0.32924461364746094,
      "learning_rate": 0.0007795216741405082,
      "loss": 0.9064,
      "step": 29500
    },
    {
      "epoch": 11.21,
      "grad_norm": 0.4220816195011139,
      "learning_rate": 0.0007757847533632287,
      "loss": 0.8883,
      "step": 30000
    },
    {
      "epoch": 11.4,
      "grad_norm": 0.35647448897361755,
      "learning_rate": 0.0007720478325859493,
      "loss": 0.8863,
      "step": 30500
    },
    {
      "epoch": 11.58,
      "grad_norm": 0.2997506260871887,
      "learning_rate": 0.0007683109118086696,
      "loss": 0.8972,
      "step": 31000
    },
    {
      "epoch": 11.77,
      "grad_norm": 0.29093658924102783,
      "learning_rate": 0.0007645739910313901,
      "loss": 0.8992,
      "step": 31500
    },
    {
      "epoch": 11.96,
      "grad_norm": 0.3531658351421356,
      "learning_rate": 0.0007608370702541107,
      "loss": 0.9006,
      "step": 32000
    },
    {
      "epoch": 12.0,
      "eval_loss": 0.8683885931968689,
      "eval_runtime": 27.5379,
      "eval_samples_per_second": 54.47,
      "eval_steps_per_second": 6.827,
      "step": 32112
    },
    {
      "epoch": 12.14,
      "grad_norm": 0.3155152201652527,
      "learning_rate": 0.0007571001494768311,
      "loss": 0.8899,
      "step": 32500
    },
    {
      "epoch": 12.33,
      "grad_norm": 0.37319883704185486,
      "learning_rate": 0.0007533632286995515,
      "loss": 0.8914,
      "step": 33000
    },
    {
      "epoch": 12.52,
      "grad_norm": 0.34216398000717163,
      "learning_rate": 0.0007496263079222721,
      "loss": 0.8832,
      "step": 33500
    },
    {
      "epoch": 12.71,
      "grad_norm": 0.36425670981407166,
      "learning_rate": 0.0007458893871449925,
      "loss": 0.8921,
      "step": 34000
    },
    {
      "epoch": 12.89,
      "grad_norm": 0.34437885880470276,
      "learning_rate": 0.000742152466367713,
      "loss": 0.893,
      "step": 34500
    },
    {
      "epoch": 13.0,
      "eval_loss": 0.8699928522109985,
      "eval_runtime": 41.391,
      "eval_samples_per_second": 36.24,
      "eval_steps_per_second": 4.542,
      "step": 34788
    },
    {
      "epoch": 13.08,
      "grad_norm": 0.38083183765411377,
      "learning_rate": 0.0007384155455904335,
      "loss": 0.8884,
      "step": 35000
    },
    {
      "epoch": 13.27,
      "grad_norm": 0.30560630559921265,
      "learning_rate": 0.0007346786248131539,
      "loss": 0.8867,
      "step": 35500
    },
    {
      "epoch": 13.45,
      "grad_norm": 0.34491968154907227,
      "learning_rate": 0.0007309417040358744,
      "loss": 0.8774,
      "step": 36000
    },
    {
      "epoch": 13.64,
      "grad_norm": 0.36239489912986755,
      "learning_rate": 0.000727204783258595,
      "loss": 0.8838,
      "step": 36500
    },
    {
      "epoch": 13.83,
      "grad_norm": 0.29625654220581055,
      "learning_rate": 0.0007234678624813154,
      "loss": 0.8852,
      "step": 37000
    },
    {
      "epoch": 14.0,
      "eval_loss": 0.871104896068573,
      "eval_runtime": 27.5945,
      "eval_samples_per_second": 54.359,
      "eval_steps_per_second": 6.813,
      "step": 37464
    },
    {
      "epoch": 14.01,
      "grad_norm": 0.35815396904945374,
      "learning_rate": 0.0007197309417040358,
      "loss": 0.8836,
      "step": 37500
    },
    {
      "epoch": 14.2,
      "grad_norm": 0.3071613311767578,
      "learning_rate": 0.0007159940209267564,
      "loss": 0.86,
      "step": 38000
    },
    {
      "epoch": 14.39,
      "grad_norm": 0.358426958322525,
      "learning_rate": 0.0007122571001494768,
      "loss": 0.8745,
      "step": 38500
    },
    {
      "epoch": 14.57,
      "grad_norm": 0.32852908968925476,
      "learning_rate": 0.0007085201793721974,
      "loss": 0.8848,
      "step": 39000
    },
    {
      "epoch": 14.76,
      "grad_norm": 0.3328881859779358,
      "learning_rate": 0.0007047832585949178,
      "loss": 0.8921,
      "step": 39500
    },
    {
      "epoch": 14.95,
      "grad_norm": 0.37583139538764954,
      "learning_rate": 0.0007010463378176383,
      "loss": 0.8889,
      "step": 40000
    },
    {
      "epoch": 15.0,
      "eval_loss": 0.8703974485397339,
      "eval_runtime": 27.5528,
      "eval_samples_per_second": 54.441,
      "eval_steps_per_second": 6.823,
      "step": 40140
    },
    {
      "epoch": 15.13,
      "grad_norm": 0.3460370600223541,
      "learning_rate": 0.0006973094170403588,
      "loss": 0.849,
      "step": 40500
    },
    {
      "epoch": 15.32,
      "grad_norm": 0.35077640414237976,
      "learning_rate": 0.0006935724962630793,
      "loss": 0.8741,
      "step": 41000
    },
    {
      "epoch": 15.51,
      "grad_norm": 0.31507641077041626,
      "learning_rate": 0.0006898355754857997,
      "loss": 0.8697,
      "step": 41500
    },
    {
      "epoch": 15.7,
      "grad_norm": 0.358271986246109,
      "learning_rate": 0.0006860986547085201,
      "loss": 0.8803,
      "step": 42000
    },
    {
      "epoch": 15.88,
      "grad_norm": 0.40432122349739075,
      "learning_rate": 0.0006823617339312407,
      "loss": 0.8789,
      "step": 42500
    },
    {
      "epoch": 16.0,
      "eval_loss": 0.8705857992172241,
      "eval_runtime": 27.5571,
      "eval_samples_per_second": 54.432,
      "eval_steps_per_second": 6.822,
      "step": 42816
    },
    {
      "epoch": 16.07,
      "grad_norm": 0.3271617591381073,
      "learning_rate": 0.0006786248131539612,
      "loss": 0.8702,
      "step": 43000
    },
    {
      "epoch": 16.26,
      "grad_norm": 0.2938063144683838,
      "learning_rate": 0.0006748878923766815,
      "loss": 0.8536,
      "step": 43500
    },
    {
      "epoch": 16.44,
      "grad_norm": 0.31256672739982605,
      "learning_rate": 0.0006711509715994021,
      "loss": 0.8578,
      "step": 44000
    },
    {
      "epoch": 16.63,
      "grad_norm": 0.41412487626075745,
      "learning_rate": 0.0006674140508221226,
      "loss": 0.88,
      "step": 44500
    },
    {
      "epoch": 16.82,
      "grad_norm": 0.33093395829200745,
      "learning_rate": 0.000663677130044843,
      "loss": 0.8789,
      "step": 45000
    },
    {
      "epoch": 17.0,
      "eval_loss": 0.8689427971839905,
      "eval_runtime": 27.5565,
      "eval_samples_per_second": 54.434,
      "eval_steps_per_second": 6.822,
      "step": 45492
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.2871299386024475,
      "learning_rate": 0.0006599402092675636,
      "loss": 0.8849,
      "step": 45500
    },
    {
      "epoch": 17.19,
      "grad_norm": 0.33953672647476196,
      "learning_rate": 0.000656203288490284,
      "loss": 0.8487,
      "step": 46000
    },
    {
      "epoch": 17.38,
      "grad_norm": 0.32505735754966736,
      "learning_rate": 0.0006524663677130045,
      "loss": 0.8494,
      "step": 46500
    },
    {
      "epoch": 17.56,
      "grad_norm": 0.2793521583080292,
      "learning_rate": 0.000648729446935725,
      "loss": 0.8788,
      "step": 47000
    },
    {
      "epoch": 17.75,
      "grad_norm": 0.36864808201789856,
      "learning_rate": 0.0006449925261584455,
      "loss": 0.8752,
      "step": 47500
    },
    {
      "epoch": 17.94,
      "grad_norm": 0.2974683344364166,
      "learning_rate": 0.0006412556053811658,
      "loss": 0.8739,
      "step": 48000
    },
    {
      "epoch": 18.0,
      "eval_loss": 0.8701769113540649,
      "eval_runtime": 27.5651,
      "eval_samples_per_second": 54.417,
      "eval_steps_per_second": 6.82,
      "step": 48168
    },
    {
      "epoch": 18.12,
      "grad_norm": 0.28446081280708313,
      "learning_rate": 0.0006375186846038864,
      "loss": 0.8525,
      "step": 48500
    },
    {
      "epoch": 18.31,
      "grad_norm": 0.3553541302680969,
      "learning_rate": 0.0006337817638266069,
      "loss": 0.8538,
      "step": 49000
    },
    {
      "epoch": 18.5,
      "grad_norm": 0.4155409038066864,
      "learning_rate": 0.0006300448430493274,
      "loss": 0.8566,
      "step": 49500
    },
    {
      "epoch": 18.68,
      "grad_norm": 0.42237982153892517,
      "learning_rate": 0.0006263079222720478,
      "loss": 0.865,
      "step": 50000
    },
    {
      "epoch": 18.87,
      "grad_norm": 0.33726340532302856,
      "learning_rate": 0.0006225710014947683,
      "loss": 0.864,
      "step": 50500
    },
    {
      "epoch": 19.0,
      "eval_loss": 0.8654464483261108,
      "eval_runtime": 27.5816,
      "eval_samples_per_second": 54.384,
      "eval_steps_per_second": 6.816,
      "step": 50844
    },
    {
      "epoch": 19.06,
      "grad_norm": 0.32216426730155945,
      "learning_rate": 0.0006188340807174889,
      "loss": 0.857,
      "step": 51000
    },
    {
      "epoch": 19.25,
      "grad_norm": 0.34868451952934265,
      "learning_rate": 0.0006150971599402093,
      "loss": 0.8495,
      "step": 51500
    },
    {
      "epoch": 19.43,
      "grad_norm": 0.2872961461544037,
      "learning_rate": 0.0006113602391629297,
      "loss": 0.8489,
      "step": 52000
    },
    {
      "epoch": 19.62,
      "grad_norm": 0.33746787905693054,
      "learning_rate": 0.0006076233183856503,
      "loss": 0.8554,
      "step": 52500
    },
    {
      "epoch": 19.81,
      "grad_norm": 0.33304259181022644,
      "learning_rate": 0.0006038863976083707,
      "loss": 0.8619,
      "step": 53000
    },
    {
      "epoch": 19.99,
      "grad_norm": 0.33472922444343567,
      "learning_rate": 0.0006001494768310912,
      "loss": 0.8646,
      "step": 53500
    },
    {
      "epoch": 20.0,
      "eval_loss": 0.8682340383529663,
      "eval_runtime": 27.5767,
      "eval_samples_per_second": 54.394,
      "eval_steps_per_second": 6.817,
      "step": 53520
    },
    {
      "epoch": 20.18,
      "grad_norm": 0.34792912006378174,
      "learning_rate": 0.0005964125560538117,
      "loss": 0.838,
      "step": 54000
    },
    {
      "epoch": 20.37,
      "grad_norm": 0.36368176341056824,
      "learning_rate": 0.0005926756352765321,
      "loss": 0.8403,
      "step": 54500
    },
    {
      "epoch": 20.55,
      "grad_norm": 0.3460724949836731,
      "learning_rate": 0.0005889387144992526,
      "loss": 0.8545,
      "step": 55000
    },
    {
      "epoch": 20.74,
      "grad_norm": 0.3103804886341095,
      "learning_rate": 0.0005852017937219732,
      "loss": 0.8609,
      "step": 55500
    },
    {
      "epoch": 20.93,
      "grad_norm": 0.3688817620277405,
      "learning_rate": 0.0005814648729446936,
      "loss": 0.8646,
      "step": 56000
    },
    {
      "epoch": 21.0,
      "eval_loss": 0.8666993975639343,
      "eval_runtime": 27.5642,
      "eval_samples_per_second": 54.418,
      "eval_steps_per_second": 6.82,
      "step": 56196
    },
    {
      "epoch": 21.11,
      "grad_norm": 0.44426316022872925,
      "learning_rate": 0.000577727952167414,
      "loss": 0.8351,
      "step": 56500
    },
    {
      "epoch": 21.3,
      "grad_norm": 0.399248331785202,
      "learning_rate": 0.0005739910313901346,
      "loss": 0.824,
      "step": 57000
    },
    {
      "epoch": 21.49,
      "grad_norm": 0.3825589120388031,
      "learning_rate": 0.000570254110612855,
      "loss": 0.84,
      "step": 57500
    },
    {
      "epoch": 21.67,
      "grad_norm": 0.35650208592414856,
      "learning_rate": 0.0005665171898355755,
      "loss": 0.8492,
      "step": 58000
    },
    {
      "epoch": 21.86,
      "grad_norm": 0.4511115849018097,
      "learning_rate": 0.000562780269058296,
      "loss": 0.8601,
      "step": 58500
    },
    {
      "epoch": 22.0,
      "eval_loss": 0.8654718399047852,
      "eval_runtime": 27.5741,
      "eval_samples_per_second": 54.399,
      "eval_steps_per_second": 6.818,
      "step": 58872
    },
    {
      "epoch": 22.05,
      "grad_norm": 0.3512158691883087,
      "learning_rate": 0.0005590433482810164,
      "loss": 0.8517,
      "step": 59000
    },
    {
      "epoch": 22.23,
      "grad_norm": 0.32915768027305603,
      "learning_rate": 0.0005553064275037369,
      "loss": 0.8287,
      "step": 59500
    },
    {
      "epoch": 22.42,
      "grad_norm": 0.33950674533843994,
      "learning_rate": 0.0005515695067264575,
      "loss": 0.8389,
      "step": 60000
    },
    {
      "epoch": 22.61,
      "grad_norm": 0.3480716943740845,
      "learning_rate": 0.0005478325859491778,
      "loss": 0.8258,
      "step": 60500
    },
    {
      "epoch": 22.8,
      "grad_norm": 0.318246066570282,
      "learning_rate": 0.0005440956651718983,
      "loss": 0.8553,
      "step": 61000
    },
    {
      "epoch": 22.98,
      "grad_norm": 0.32425710558891296,
      "learning_rate": 0.0005403587443946189,
      "loss": 0.8567,
      "step": 61500
    },
    {
      "epoch": 23.0,
      "eval_loss": 0.8665488362312317,
      "eval_runtime": 27.5952,
      "eval_samples_per_second": 54.357,
      "eval_steps_per_second": 6.813,
      "step": 61548
    },
    {
      "epoch": 23.17,
      "grad_norm": 0.3930468261241913,
      "learning_rate": 0.0005366218236173394,
      "loss": 0.8287,
      "step": 62000
    },
    {
      "epoch": 23.36,
      "grad_norm": 0.3356584310531616,
      "learning_rate": 0.0005328849028400597,
      "loss": 0.8286,
      "step": 62500
    },
    {
      "epoch": 23.54,
      "grad_norm": 0.321384459733963,
      "learning_rate": 0.0005291479820627803,
      "loss": 0.8363,
      "step": 63000
    },
    {
      "epoch": 23.73,
      "grad_norm": 0.3376687169075012,
      "learning_rate": 0.0005254110612855008,
      "loss": 0.8382,
      "step": 63500
    },
    {
      "epoch": 23.92,
      "grad_norm": 0.3785463869571686,
      "learning_rate": 0.0005216741405082212,
      "loss": 0.8512,
      "step": 64000
    },
    {
      "epoch": 24.0,
      "eval_loss": 0.8660637140274048,
      "eval_runtime": 27.5813,
      "eval_samples_per_second": 54.385,
      "eval_steps_per_second": 6.816,
      "step": 64224
    },
    {
      "epoch": 24.1,
      "grad_norm": 0.40164914727211,
      "learning_rate": 0.0005179372197309418,
      "loss": 0.8297,
      "step": 64500
    },
    {
      "epoch": 24.29,
      "grad_norm": 0.39735671877861023,
      "learning_rate": 0.0005142002989536622,
      "loss": 0.8262,
      "step": 65000
    },
    {
      "epoch": 24.48,
      "grad_norm": 0.37332844734191895,
      "learning_rate": 0.0005104633781763826,
      "loss": 0.8301,
      "step": 65500
    },
    {
      "epoch": 24.66,
      "grad_norm": 0.34184372425079346,
      "learning_rate": 0.0005067264573991032,
      "loss": 0.8254,
      "step": 66000
    },
    {
      "epoch": 24.85,
      "grad_norm": 0.2986793518066406,
      "learning_rate": 0.0005029895366218237,
      "loss": 0.8393,
      "step": 66500
    },
    {
      "epoch": 25.0,
      "eval_loss": 0.8639548420906067,
      "eval_runtime": 27.5638,
      "eval_samples_per_second": 54.419,
      "eval_steps_per_second": 6.821,
      "step": 66900
    },
    {
      "epoch": 25.04,
      "grad_norm": 0.33199504017829895,
      "learning_rate": 0.0004992526158445441,
      "loss": 0.8424,
      "step": 67000
    },
    {
      "epoch": 25.22,
      "grad_norm": 0.31877031922340393,
      "learning_rate": 0.0004955156950672646,
      "loss": 0.814,
      "step": 67500
    },
    {
      "epoch": 25.41,
      "grad_norm": 0.26200157403945923,
      "learning_rate": 0.0004917787742899851,
      "loss": 0.835,
      "step": 68000
    },
    {
      "epoch": 25.6,
      "grad_norm": 0.394488126039505,
      "learning_rate": 0.00048804185351270554,
      "loss": 0.827,
      "step": 68500
    },
    {
      "epoch": 25.78,
      "grad_norm": 0.3257158696651459,
      "learning_rate": 0.000484304932735426,
      "loss": 0.8237,
      "step": 69000
    },
    {
      "epoch": 25.97,
      "grad_norm": 0.28965097665786743,
      "learning_rate": 0.00048056801195814645,
      "loss": 0.8382,
      "step": 69500
    },
    {
      "epoch": 26.0,
      "eval_loss": 0.8679524660110474,
      "eval_runtime": 27.5742,
      "eval_samples_per_second": 54.399,
      "eval_steps_per_second": 6.818,
      "step": 69576
    },
    {
      "epoch": 26.16,
      "grad_norm": 0.33901745080947876,
      "learning_rate": 0.000476831091180867,
      "loss": 0.8258,
      "step": 70000
    },
    {
      "epoch": 26.35,
      "grad_norm": 0.3985837996006012,
      "learning_rate": 0.0004730941704035874,
      "loss": 0.8116,
      "step": 70500
    },
    {
      "epoch": 26.53,
      "grad_norm": 0.30396515130996704,
      "learning_rate": 0.00046935724962630796,
      "loss": 0.8212,
      "step": 71000
    },
    {
      "epoch": 26.72,
      "grad_norm": 0.34819290041923523,
      "learning_rate": 0.0004656203288490284,
      "loss": 0.8265,
      "step": 71500
    },
    {
      "epoch": 26.91,
      "grad_norm": 0.4075728952884674,
      "learning_rate": 0.0004618834080717489,
      "loss": 0.8269,
      "step": 72000
    },
    {
      "epoch": 27.0,
      "eval_loss": 0.8642496466636658,
      "eval_runtime": 27.5717,
      "eval_samples_per_second": 54.404,
      "eval_steps_per_second": 6.819,
      "step": 72252
    },
    {
      "epoch": 27.09,
      "grad_norm": 0.40458372235298157,
      "learning_rate": 0.0004581464872944694,
      "loss": 0.8267,
      "step": 72500
    },
    {
      "epoch": 27.28,
      "grad_norm": 0.3331370949745178,
      "learning_rate": 0.00045440956651718984,
      "loss": 0.8212,
      "step": 73000
    },
    {
      "epoch": 27.47,
      "grad_norm": 0.303014874458313,
      "learning_rate": 0.0004506726457399103,
      "loss": 0.8049,
      "step": 73500
    },
    {
      "epoch": 27.65,
      "grad_norm": 0.2830602526664734,
      "learning_rate": 0.0004469357249626308,
      "loss": 0.822,
      "step": 74000
    },
    {
      "epoch": 27.84,
      "grad_norm": 0.3773767352104187,
      "learning_rate": 0.0004431988041853513,
      "loss": 0.8243,
      "step": 74500
    },
    {
      "epoch": 28.0,
      "eval_loss": 0.870171308517456,
      "eval_runtime": 27.5914,
      "eval_samples_per_second": 54.365,
      "eval_steps_per_second": 6.814,
      "step": 74928
    },
    {
      "epoch": 28.03,
      "grad_norm": 0.3706819713115692,
      "learning_rate": 0.0004394618834080717,
      "loss": 0.8271,
      "step": 75000
    },
    {
      "epoch": 28.21,
      "grad_norm": 0.4147716760635376,
      "learning_rate": 0.00043572496263079226,
      "loss": 0.7887,
      "step": 75500
    },
    {
      "epoch": 28.4,
      "grad_norm": 0.35047900676727295,
      "learning_rate": 0.0004319880418535127,
      "loss": 0.8038,
      "step": 76000
    },
    {
      "epoch": 28.59,
      "grad_norm": 0.41960182785987854,
      "learning_rate": 0.00042825112107623323,
      "loss": 0.8277,
      "step": 76500
    },
    {
      "epoch": 28.77,
      "grad_norm": 0.3344414234161377,
      "learning_rate": 0.00042451420029895366,
      "loss": 0.822,
      "step": 77000
    },
    {
      "epoch": 28.96,
      "grad_norm": 0.32228443026542664,
      "learning_rate": 0.00042077727952167414,
      "loss": 0.8288,
      "step": 77500
    },
    {
      "epoch": 29.0,
      "eval_loss": 0.8690592646598816,
      "eval_runtime": 27.6045,
      "eval_samples_per_second": 54.339,
      "eval_steps_per_second": 6.81,
      "step": 77604
    },
    {
      "epoch": 29.15,
      "grad_norm": 0.33978766202926636,
      "learning_rate": 0.00041704035874439463,
      "loss": 0.8168,
      "step": 78000
    },
    {
      "epoch": 29.33,
      "grad_norm": 0.3489602506160736,
      "learning_rate": 0.0004133034379671151,
      "loss": 0.8063,
      "step": 78500
    },
    {
      "epoch": 29.52,
      "grad_norm": 0.3553938567638397,
      "learning_rate": 0.00040956651718983554,
      "loss": 0.8055,
      "step": 79000
    },
    {
      "epoch": 29.71,
      "grad_norm": 0.3309650719165802,
      "learning_rate": 0.0004058295964125561,
      "loss": 0.8044,
      "step": 79500
    },
    {
      "epoch": 29.9,
      "grad_norm": 0.4095553159713745,
      "learning_rate": 0.0004020926756352765,
      "loss": 0.8205,
      "step": 80000
    },
    {
      "epoch": 30.0,
      "eval_loss": 0.8676280379295349,
      "eval_runtime": 27.5989,
      "eval_samples_per_second": 54.35,
      "eval_steps_per_second": 6.812,
      "step": 80280
    },
    {
      "epoch": 30.08,
      "grad_norm": 0.33799800276756287,
      "learning_rate": 0.000398355754857997,
      "loss": 0.8092,
      "step": 80500
    },
    {
      "epoch": 30.27,
      "grad_norm": 0.3220522105693817,
      "learning_rate": 0.0003946188340807175,
      "loss": 0.7913,
      "step": 81000
    },
    {
      "epoch": 30.46,
      "grad_norm": 0.4006996750831604,
      "learning_rate": 0.00039088191330343796,
      "loss": 0.7979,
      "step": 81500
    },
    {
      "epoch": 30.64,
      "grad_norm": 0.316152960062027,
      "learning_rate": 0.0003871449925261585,
      "loss": 0.8083,
      "step": 82000
    },
    {
      "epoch": 30.83,
      "grad_norm": 0.36684781312942505,
      "learning_rate": 0.00038340807174887893,
      "loss": 0.8211,
      "step": 82500
    },
    {
      "epoch": 31.0,
      "eval_loss": 0.8711792230606079,
      "eval_runtime": 27.5857,
      "eval_samples_per_second": 54.376,
      "eval_steps_per_second": 6.815,
      "step": 82956
    },
    {
      "epoch": 31.02,
      "grad_norm": 0.3612896800041199,
      "learning_rate": 0.0003796711509715994,
      "loss": 0.8177,
      "step": 83000
    },
    {
      "epoch": 31.2,
      "grad_norm": 0.3449060320854187,
      "learning_rate": 0.0003759342301943199,
      "loss": 0.794,
      "step": 83500
    },
    {
      "epoch": 31.39,
      "grad_norm": 0.4054742753505707,
      "learning_rate": 0.0003721973094170404,
      "loss": 0.7993,
      "step": 84000
    },
    {
      "epoch": 31.58,
      "grad_norm": 0.37817317247390747,
      "learning_rate": 0.0003684603886397608,
      "loss": 0.8062,
      "step": 84500
    },
    {
      "epoch": 31.76,
      "grad_norm": 0.38825997710227966,
      "learning_rate": 0.00036472346786248135,
      "loss": 0.8089,
      "step": 85000
    },
    {
      "epoch": 31.95,
      "grad_norm": 0.4765758514404297,
      "learning_rate": 0.0003609865470852018,
      "loss": 0.805,
      "step": 85500
    },
    {
      "epoch": 32.0,
      "eval_loss": 0.8647703528404236,
      "eval_runtime": 27.5965,
      "eval_samples_per_second": 54.355,
      "eval_steps_per_second": 6.812,
      "step": 85632
    },
    {
      "epoch": 32.14,
      "grad_norm": 0.36426928639411926,
      "learning_rate": 0.00035724962630792227,
      "loss": 0.7992,
      "step": 86000
    },
    {
      "epoch": 32.32,
      "grad_norm": 0.4005228579044342,
      "learning_rate": 0.00035351270553064275,
      "loss": 0.7962,
      "step": 86500
    },
    {
      "epoch": 32.51,
      "grad_norm": 0.37696558237075806,
      "learning_rate": 0.00034977578475336324,
      "loss": 0.8034,
      "step": 87000
    },
    {
      "epoch": 32.7,
      "grad_norm": 0.4847320318222046,
      "learning_rate": 0.0003460388639760837,
      "loss": 0.7936,
      "step": 87500
    },
    {
      "epoch": 32.88,
      "grad_norm": 0.30746257305145264,
      "learning_rate": 0.0003423019431988042,
      "loss": 0.8088,
      "step": 88000
    },
    {
      "epoch": 33.0,
      "eval_loss": 0.8708198070526123,
      "eval_runtime": 27.5855,
      "eval_samples_per_second": 54.376,
      "eval_steps_per_second": 6.815,
      "step": 88308
    },
    {
      "epoch": 33.07,
      "grad_norm": 0.40459391474723816,
      "learning_rate": 0.00033856502242152463,
      "loss": 0.7895,
      "step": 88500
    },
    {
      "epoch": 33.26,
      "grad_norm": 0.36297979950904846,
      "learning_rate": 0.00033482810164424517,
      "loss": 0.8023,
      "step": 89000
    },
    {
      "epoch": 33.45,
      "grad_norm": 0.33659613132476807,
      "learning_rate": 0.0003310911808669656,
      "loss": 0.7808,
      "step": 89500
    },
    {
      "epoch": 33.63,
      "grad_norm": 0.3946462571620941,
      "learning_rate": 0.0003273542600896861,
      "loss": 0.7917,
      "step": 90000
    },
    {
      "epoch": 33.82,
      "grad_norm": 0.40666940808296204,
      "learning_rate": 0.0003236173393124066,
      "loss": 0.7935,
      "step": 90500
    },
    {
      "epoch": 34.0,
      "eval_loss": 0.8723837733268738,
      "eval_runtime": 27.5883,
      "eval_samples_per_second": 54.371,
      "eval_steps_per_second": 6.814,
      "step": 90984
    },
    {
      "epoch": 34.01,
      "grad_norm": 0.32181206345558167,
      "learning_rate": 0.00031988041853512705,
      "loss": 0.8033,
      "step": 91000
    },
    {
      "epoch": 34.19,
      "grad_norm": 0.447453111410141,
      "learning_rate": 0.00031614349775784754,
      "loss": 0.7813,
      "step": 91500
    },
    {
      "epoch": 34.38,
      "grad_norm": 0.3787081837654114,
      "learning_rate": 0.000312406576980568,
      "loss": 0.7845,
      "step": 92000
    },
    {
      "epoch": 34.57,
      "grad_norm": 0.42036929726600647,
      "learning_rate": 0.0003086696562032885,
      "loss": 0.7941,
      "step": 92500
    },
    {
      "epoch": 34.75,
      "grad_norm": 0.4203657805919647,
      "learning_rate": 0.000304932735426009,
      "loss": 0.8042,
      "step": 93000
    },
    {
      "epoch": 34.94,
      "grad_norm": 0.3521190285682678,
      "learning_rate": 0.0003011958146487295,
      "loss": 0.7897,
      "step": 93500
    },
    {
      "epoch": 35.0,
      "eval_loss": 0.8701834082603455,
      "eval_runtime": 27.5771,
      "eval_samples_per_second": 54.393,
      "eval_steps_per_second": 6.817,
      "step": 93660
    },
    {
      "epoch": 35.13,
      "grad_norm": 0.4176621735095978,
      "learning_rate": 0.0002974588938714499,
      "loss": 0.7838,
      "step": 94000
    },
    {
      "epoch": 35.31,
      "grad_norm": 0.35834240913391113,
      "learning_rate": 0.00029372197309417044,
      "loss": 0.7879,
      "step": 94500
    },
    {
      "epoch": 35.5,
      "grad_norm": 0.4033310115337372,
      "learning_rate": 0.0002899850523168909,
      "loss": 0.7819,
      "step": 95000
    },
    {
      "epoch": 35.69,
      "grad_norm": 0.4199840724468231,
      "learning_rate": 0.00028624813153961136,
      "loss": 0.7818,
      "step": 95500
    },
    {
      "epoch": 35.87,
      "grad_norm": 0.40174490213394165,
      "learning_rate": 0.00028251121076233184,
      "loss": 0.8015,
      "step": 96000
    },
    {
      "epoch": 36.0,
      "eval_loss": 0.8727173805236816,
      "eval_runtime": 27.5897,
      "eval_samples_per_second": 54.368,
      "eval_steps_per_second": 6.814,
      "step": 96336
    }
  ],
  "logging_steps": 500,
  "max_steps": 133800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "total_flos": 9.321642052603085e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
